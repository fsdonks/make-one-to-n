{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAA Post Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Capacity Analysis Run with Default Initial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demandtrends folder\n",
    "root=\"/home/craig/runs/big_test/base-testdata-v7/\"\n",
    "dtrends = root+ \"DemandTrends.txt\"\n",
    "df=pd.read_csv(dtrends, sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot a line chart of TotalRequired and Deployed, we group by time and sum the values so that we have the total TotalRequired and Deployed for each day.  If you don't reset_index, you get a multi-index dataframe from groupby, which you can't plot, but functions called on groupby (like sum() here) will sum the values in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = df.groupby(['t']).sum().reset_index()\n",
    "group_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot('t', 'TotalRequired', data=group_df)\n",
    "plt.plot('t', 'Deployed', data=group_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Initial Conditions Output Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been storing the results the the parent directory alongside the MARATHON workbook.  results.txt is from random initial condition runs from marathon.analysis.random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = root+ \"../results.txt\" \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(results, sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we count the number records for each \\[SRC, AC\\] group.  For x initial condition reps and y phases, we should have x*y records.  This is essentially pivoting in Python by count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = df.groupby(by=['SRC', 'AC']).count().reset_index()\n",
    "group_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for any \\[SRC, AC\\] tuple that doesn't have x*y records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df[group_df['rep-seed']!=12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to compute Score and Excess for each \\[SRC, AC\\] tuple.  \n",
    "\n",
    "First, average NG fill, then average RC fill, then average NG fill, then sum and divide by demand for Score (note that fill is fill from demandtrends and NOT just deployed like the field was renamed in 2327)\n",
    "Excess is sum of available for each component divided by demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute % demand met (dmet) and % excess over the demand (emet) \n",
    "#first by phase (use average group by with src, ac, phase)\n",
    "def by_phase_percentages(results_df):\n",
    "    group_df = results_df.groupby(by=['SRC', 'AC', 'phase']).mean().reset_index()\n",
    "    group_df['dmet'] = (group_df['NG-fill'] + group_df['AC-fill'] + group_df['RC-fill']) / group_df['total-quantity']\n",
    "    group_df['emet'] = (group_df['NG-deployable'] + \n",
    "                        group_df['AC-deployable'] + \n",
    "                        group_df['RC-deployable']) / group_df['total-quantity']\n",
    "    group_df.head()\n",
    "    return group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights used for a weighted score.\n",
    "phase_weights= {\"comp1\" : 0.125,\n",
    "               \"comp2\" : 0.125,\n",
    "               \"phase1\" : .0625,\n",
    "               \"phase2\" : .0625,\n",
    "               \"phase3\" : .5,\n",
    "               \"phase4\" : .125}\n",
    "\n",
    "#add the weight to each row\n",
    "def row_weight(row):\n",
    "    return phase_weights[row['phase']]\n",
    "\n",
    "#then group by src, ac, using custom function for weighted phases\n",
    "def weighted_average(df, data_col, weight_col, by_col):\n",
    "    df['weight']=df.apply(lambda row: row_weight(row), axis=1)\n",
    "    df['_data_times_weight'] = df[data_col] * df[weight_col]\n",
    "    g = df.groupby(by=by_col)\n",
    "    #note that if we're missing a phase, the weight is adjusted accordingly\n",
    "    res = g['_data_times_weight'].sum() / g[weight_col].sum()\n",
    "    del df['_data_times_weight']\n",
    "    return res\n",
    "\n",
    "def by_src_inventory_scores(percentages_df):\n",
    "    inventory_score = weighted_average(percentages_df, 'dmet', 'weight', ['SRC', 'AC'])\n",
    "    inventory_excess = weighted_average(percentages_df, 'emet', 'weight', ['SRC', 'AC'])\n",
    "    res_df=inventory_score.reset_index().rename(columns={0 : \"Score\"})\n",
    "    #join both Score and Excess results.\n",
    "    res_df = res_df.merge(inventory_excess.reset_index().rename(columns={0 : 'Excess'}), how='inner', on=['SRC', 'AC'])\n",
    "    return res_df\n",
    "\n",
    "def by_src_ac_scores(results_path):\n",
    "    df=pd.read_csv(results_path, sep='\\t')\n",
    "    return by_src_inventory_scores(by_phase_percentages(df))\n",
    "\n",
    "by_src_ac_scores(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat this for the other demand\n",
    "#join tables so that you have two score columns\n",
    "#add column called min_score\n",
    "#add another column called min_score_demand\n",
    "#could turn this into a map to concat both demand tables then, but not necessary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
